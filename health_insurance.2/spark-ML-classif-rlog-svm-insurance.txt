
val df = spark.read.format("csv").option("header","true").option("inferSchema","true").load("insurance/insurance.train.csv")

df.printSchema
root
 |-- id: integer (nullable = true)
 |-- Gender: string (nullable = true)
 |-- Age: integer (nullable = true)
 |-- Driving_License: integer (nullable = true)
 |-- Region_Code: double (nullable = true)
 |-- Previously_Insured: integer (nullable = true)
 |-- Vehicle_Age: string (nullable = true)
 |-- Vehicle_Damage: string (nullable = true)
 |-- Annual_Premium: double (nullable = true)
 |-- Policy_Sales_Channel: double (nullable = true)
 |-- Vintage: integer (nullable = true)
 |-- Response: integer (nullable = true)

df.show
+---+------+---+---------------+-----------+------------------+-----------+--------------+--------------+--------------------+-------+--------+
| id|Gender|Age|Driving_License|Region_Code|Previously_Insured|Vehicle_Age|Vehicle_Damage|Annual_Premium|Policy_Sales_Channel|Vintage|Response|
+---+------+---+---------------+-----------+------------------+-----------+--------------+--------------+--------------------+-------+--------+
|  1|  Male| 44|              1|       28.0|                 0|  > 2 Years|           Yes|       40454.0|                26.0|    217|       1|
|  2|  Male| 76|              1|        3.0|                 0|   1-2 Year|            No|       33536.0|                26.0|    183|       0|
|  3|  Male| 47|              1|       28.0|                 0|  > 2 Years|           Yes|       38294.0|                26.0|     27|       1|
|  4|  Male| 21|              1|       11.0|                 1|   < 1 Year|            No|       28619.0|               152.0|    203|       0|
|  5|Female| 29|              1|       41.0|                 1|   < 1 Year|            No|       27496.0|               152.0|     39|       0|
|  6|Female| 24|              1|       33.0|                 0|   < 1 Year|           Yes|        2630.0|               160.0|    176|       0|
|  7|  Male| 23|              1|       11.0|                 0|   < 1 Year|           Yes|       23367.0|               152.0|    249|       0|
|  8|Female| 56|              1|       28.0|                 0|   1-2 Year|           Yes|       32031.0|                26.0|     72|       1|
|  9|Female| 24|              1|        3.0|                 1|   < 1 Year|            No|       27619.0|               152.0|     28|       0|
| 10|Female| 32|              1|        6.0|                 1|   < 1 Year|            No|       28771.0|               152.0|     80|       0|
| 11|Female| 47|              1|       35.0|                 0|   1-2 Year|           Yes|       47576.0|               124.0|     46|       1|
| 12|Female| 24|              1|       50.0|                 1|   < 1 Year|            No|       48699.0|               152.0|    289|       0|
| 13|Female| 41|              1|       15.0|                 1|   1-2 Year|            No|       31409.0|                14.0|    221|       0|
| 14|  Male| 76|              1|       28.0|                 0|   1-2 Year|           Yes|       36770.0|                13.0|     15|       0|
| 15|  Male| 71|              1|       28.0|                 1|   1-2 Year|            No|       46818.0|                30.0|     58|       0|
| 16|  Male| 37|              1|        6.0|                 0|   1-2 Year|           Yes|        2630.0|               156.0|    147|       1|
| 17|Female| 25|              1|       45.0|                 0|   < 1 Year|           Yes|       26218.0|               160.0|    256|       0|
| 18|Female| 25|              1|       35.0|                 1|   < 1 Year|            No|       46622.0|               152.0|    299|       0|
| 19|  Male| 42|              1|       28.0|                 0|   1-2 Year|           Yes|       33667.0|               124.0|    158|       0|
| 20|Female| 60|              1|       33.0|                 0|   1-2 Year|           Yes|       32363.0|               124.0|    102|       1|
+---+------+---+---------------+-----------+------------------+-----------+--------------+--------------+--------------------+-------+--------+
only showing top 20 rows


df.select("Gender","Vehicle_Age","Vehicle_Damage","Previously_Insured","Age","Vintage","Response").show
+------+-----------+--------------+------------------+---+-------+--------+
|Gender|Vehicle_Age|Vehicle_Damage|Previously_Insured|Age|Vintage|Response|
+------+-----------+--------------+------------------+---+-------+--------+
|  Male|  > 2 Years|           Yes|                 0| 44|    217|       1|
|  Male|   1-2 Year|            No|                 0| 76|    183|       0|
|  Male|  > 2 Years|           Yes|                 0| 47|     27|       1|
|  Male|   < 1 Year|            No|                 1| 21|    203|       0|
|Female|   < 1 Year|            No|                 1| 29|     39|       0|
|Female|   < 1 Year|           Yes|                 0| 24|    176|       0|
|  Male|   < 1 Year|           Yes|                 0| 23|    249|       0|
|Female|   1-2 Year|           Yes|                 0| 56|     72|       1|
|Female|   < 1 Year|            No|                 1| 24|     28|       0|
|Female|   < 1 Year|            No|                 1| 32|     80|       0|
|Female|   1-2 Year|           Yes|                 0| 47|     46|       1|
|Female|   < 1 Year|            No|                 1| 24|    289|       0|
|Female|   1-2 Year|            No|                 1| 41|    221|       0|
|  Male|   1-2 Year|           Yes|                 0| 76|     15|       0|
|  Male|   1-2 Year|            No|                 1| 71|     58|       0|
|  Male|   1-2 Year|           Yes|                 0| 37|    147|       1|
|Female|   < 1 Year|           Yes|                 0| 25|    256|       0|
|Female|   < 1 Year|            No|                 1| 25|    299|       0|
|  Male|   1-2 Year|           Yes|                 0| 42|    158|       0|
|Female|   1-2 Year|           Yes|                 0| 60|    102|       1|
+------+-----------+--------------+------------------+---+-------+--------+
only showing top 20 rows


df.select("Gender","Vehicle_Age","Vehicle_Damage","Previously_Insured","Age","Vintage","Response").describe().show
+-------+------+-----------+--------------+-------------------+------------------+------------------+-------------------+
|summary|Gender|Vehicle_Age|Vehicle_Damage| Previously_Insured|               Age|           Vintage|           Response|
+-------+------+-----------+--------------+-------------------+------------------+------------------+-------------------+
|  count|381109|     381109|        381109|             381109|            381109|            381109|             381109|
|   mean|  null|       null|          null| 0.4582101183650871|38.822583565331705|154.34739667654136|0.12256336113815208|
| stddev|  null|       null|          null|0.49825119888722647|15.511611018095289| 83.67130362658735|0.32793576478642567|
|    min|Female|   1-2 Year|            No|                  0|                20|                10|                  0|
|    max|  Male|  > 2 Years|           Yes|                  1|                85|               299|                  1|
+-------+------+-----------+--------------+-------------------+------------------+------------------+-------------------+

val df1 = df.select("Gender","Vehicle_Age","Vehicle_Damage","Previously_Insured","Age","Vintage","Response").
             withColumn("label", 'Response)

import org.apache.spark.ml.feature.{StringIndexer, OneHotEncoder, VectorAssembler}

val dfInd1 = new StringIndexer().setInputCol("Gender").setOutputCol("GenderIdx")
val dfInd2 = new StringIndexer().setInputCol("Vehicle_Age").setOutputCol("Vehicle_AgeIdx")
val dfInd3 = new StringIndexer().setInputCol("Vehicle_Damage").setOutputCol("Vehicle_DamageIdx")

val dfOne2 = new OneHotEncoder().setInputCol("Vehicle_AgeIdx").setOutputCol("Vehicle_AgeVect")

val va = new VectorAssembler().setOutputCol("features").setInputCols(Array("GenderIdx","Vehicle_AgeVect","Vehicle_DamageIdx","Previously_Insured","Age","Vintage"))

import org.apache.spark.ml.feature.StandardScaler
val stdScaler = new StandardScaler().
setWithStd(true).
setWithMean(true).
setInputCol("features").
setOutputCol("scaledFeatures")

import org.apache.spark.ml.classification.LogisticRegression
val lr = new LogisticRegression
lr.setRegParam(0.01).setMaxIter(500).setFitIntercept(true).setFeaturesCol("scaledFeatures")

import org.apache.spark.ml.Pipeline
val pipeline = new Pipeline().setStages(Array(dfInd1,dfInd2,dfInd3,dfOne2,va,stdScaler,lr))

val Array(trainingData, testData) = df1.randomSplit(Array(0.7,0.3),11L)

val model = pipeline.fit(trainingData)

val pred = model.transform(testData)

import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator
val bceval = new BinaryClassificationEvaluator()

bceval.evaluate(pred)
res1: Double = 0.832307403437676

import org.apache.spark.ml.classification.LogisticRegressionModel

val lrmodel = model.stages(6).asInstanceOf[LogisticRegressionModel]

println(s"LR Model coefficients:\n${lrmodel.coefficients.toArray.mkString("\n")}")
LR Model coefficients:
-0.04182018396971128
0.021216049193669182
-0.4514575272330213
-0.8305768756980124
-0.8725539214394099
-0.19307481877910754
-9.770249152526499E-4

-------------------

import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}

val paramGrid = new ParamGridBuilder().
addGrid(lr.regParam, Array(0.1, 0.01, 0.001)).
addGrid(lr.fitIntercept).
addGrid(lr.maxIter, Array(100,300,500)).build()

import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator

val cv = new CrossValidator().
setEstimator(pipeline).
setEvaluator(new BinaryClassificationEvaluator).
setEstimatorParamMaps(paramGrid).
setNumFolds(3)

val model = cv.fit(trainingData)

import org.apache.spark.ml.PipelineModel
val bestmodel = model.bestModel.asInstanceOf[PipelineModel]

import org.apache.spark.ml.classification.LogisticRegressionModel
val lrmodel = bestmodel.stages(6).asInstanceOf[LogisticRegressionModel]

scala> lrmodel.getRegParam
res3: Double = 0.001

scala> lrmodel.getMaxIter
res4: Int = 100

scala> lrmodel.getThreshold
res5: Double = 0.5

scala> lrmodel.getFitIntercept
res6: Boolean = true

scala> lrmodel.getStandardization
res7: Boolean = true

scala> println(s"LR Model coefficients:\n${lrmodel.coefficients.toArray.mkString("\n")}")
LR Model coefficients:
-0.0406186021517663
-0.09259974029563892
-0.6747089343775315
-1.0170285695620838
-1.4747962503024212
-0.31416168977091435
-8.243938191028616E-4

val pred = bestmodel.transform(testData)

val bceval = new BinaryClassificationEvaluator()

bceval.evaluate(pred)
res14: Double = 0.833949208675838
