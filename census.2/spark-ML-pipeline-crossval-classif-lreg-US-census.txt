
import org.apache.spark.sql.types._

val adultschema = new StructType().
 add(StructField("age",DoubleType,true)).
 add(StructField("workclass",StringType,true)).
 add(StructField("fnlwgt",DoubleType,true)).
 add(StructField("education",StringType,true)).
 add(StructField("marital_status",StringType,true)).
 add(StructField("occupation",StringType,true)).
 add(StructField("relationship",StringType,true)).
 add(StructField("race",StringType,true)).
 add(StructField("sex",StringType,true)).
 add(StructField("capital_gain",DoubleType,true)).
 add(StructField("capital_loss",DoubleType,true)).
 add(StructField("hours_per_week",DoubleType,true)).
 add(StructField("native_country",StringType,true)).
 add(StructField("income",StringType,true))
 
val dfraw = spark.read.format("csv").schema(adultschema).load("first-edition/ch08/adult.raw")

val dfrawrp = dfraw.na.replace(Array("workclass"), Map("?" -> "Private"))

val dfrawrpl = dfrawrp.na.replace(Array("occupation"), Map("?" -> "Prof-specialty"))

val dfrawnona = dfrawrpl.na.replace(Array("native_country"), Map("?" -> "United-States"))

---------------------

import org.apache.spark.ml.feature.{StringIndexer, OneHotEncoder, VectorAssembler}

val dfInd1 = new StringIndexer().setInputCol("workclass").setOutputCol("workclassCat").
fit(dfrawnona).transform(dfrawnona)

val dfInd2 = new StringIndexer().setInputCol("education").setOutputCol("educationCat").
fit(dfInd1).transform(dfInd1)

val dfInd3 = new StringIndexer().setInputCol("marital_status").setOutputCol("marital_statusCat").
fit(dfInd2).transform(dfInd2)

val dfInd9 = new StringIndexer().setInputCol("income").setOutputCol("label").
fit(dfInd3).transform(dfInd3)

val dfOne1 = new OneHotEncoder().setInputCol("workclassCat").setOutputCol("workclassVect").
transform(dfInd9).drop("workclassCat")

val dfOne2 = new OneHotEncoder().setInputCol("educationCat").setOutputCol("educationVect").
transform(dfOne1).drop("educationCat")

val dfOne3 = new OneHotEncoder().setInputCol("marital_statusCat").setOutputCol("marital_statusVect").
transform(dfOne2).drop("marital_statusCat")

val va = new VectorAssembler().setOutputCol("features").setInputCols(Array("age","workclassVect","educationVect","marital_statusVect"))

val lpoints = va.transform(dfOne3).select("features","label")

val splits = lpoints.randomSplit(Array(0.7,0.3),11L)
val trainingData = splits(0).cache()
val testData = splits(1).cache()

import org.apache.spark.ml.classification.LogisticRegression
val lr = new LogisticRegression()
lr.setRegParam(0.01).setMaxIter(500).setFitIntercept(true)
val lrmodel = lr.fit(trainingData)

val pred = lrmodel.transform(testData)

import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator
val bceval = new BinaryClassificationEvaluator()

bceval.evaluate(pred)
// bceval.getMetricName


----- using ML Pipeline

val Array(trainingData, testData) = dfrawnona.randomSplit(Array(0.7,0.3),11L)

import org.apache.spark.ml.feature.{StringIndexer, OneHotEncoder, VectorAssembler}

val dfInd1 = new StringIndexer().setInputCol("workclass").setOutputCol("workclassCat")
val dfInd2 = new StringIndexer().setInputCol("education").setOutputCol("educationCat")
val dfInd3 = new StringIndexer().setInputCol("marital_status").setOutputCol("marital_statusCat")
val dfInd4 = new StringIndexer().setInputCol("occupation").setOutputCol("occupationCat")
val dfInd5 = new StringIndexer().setInputCol("relationship").setOutputCol("relationshipCat")
val dfInd6 = new StringIndexer().setInputCol("race").setOutputCol("raceCat")
val dfInd7 = new StringIndexer().setInputCol("sex").setOutputCol("sexCat")
val dfInd8 = new StringIndexer().setInputCol("native_country").setOutputCol("native_countryCat").setHandleInvalid("keep")
val dfInd9 = new StringIndexer().setInputCol("income").setOutputCol("label")

val dfOne1 = new OneHotEncoder().setInputCol("workclassCat").setOutputCol("workclassVect")
val dfOne2 = new OneHotEncoder().setInputCol("educationCat").setOutputCol("educationVect")
val dfOne3 = new OneHotEncoder().setInputCol("marital_statusCat").setOutputCol("marital_statusVect")
val dfOne4 = new OneHotEncoder().setInputCol("occupationCat").setOutputCol("occupationVect")
val dfOne5 = new OneHotEncoder().setInputCol("relationshipCat").setOutputCol("relationshipVect")
val dfOne6 = new OneHotEncoder().setInputCol("raceCat").setOutputCol("raceVect")
val dfOne7 = new OneHotEncoder().setInputCol("sexCat").setOutputCol("sexVect")
val dfOne8 = new OneHotEncoder().setInputCol("native_countryCat").setOutputCol("native_countryVect")

val va = new VectorAssembler().setOutputCol("features").setInputCols(Array("age","workclassVect","fnlwgt","educationVect","marital_statusVect","occupationVect","relationshipVect","raceVect","sexVect","capital_gain","capital_loss","hours_per_week","native_countryVect","label"))

import org.apache.spark.ml.classification.LogisticRegression
val lr = new LogisticRegression()
lr.setRegParam(0.01).setMaxIter(500).setFitIntercept(true)

import org.apache.spark.ml.Pipeline

val pipeline = new Pipeline().setStages(Array(dfInd1,dfInd2,dfInd3,dfInd4,dfInd5,dfInd6,dfInd7,dfInd8,dfInd9,dfOne1,dfOne2,dfOne3,dfOne4,dfOne5,dfOne6,dfOne7,dfOne8,va,lr))

val model = pipeline.fit(trainingData)

val pred = model.transform(testData)

import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator
val bceval = new BinaryClassificationEvaluator()

bceval.evaluate(pred)
res4: Double = 1.0

import org.apache.spark.ml.classification.LogisticRegressionModel

val lrmodel = model.stages(18).asInstanceOf[LogisticRegressionModel]

println(s"LR Model coefficients:\n${lrmodel.coefficients.toArray.mkString("\n")}")
LR Model coefficients:
0.010453418831390887
0.015974684865988818
-0.10042620255612315
0.011017216243100134
-0.156872431299507
-0.04704410650567543
0.19371950435000485
0.24676867941738403
-0.19646322628729687
1.9036924842636436E-7
-0.15935983477309817
-0.016885947509907462
0.3104740962833
0.44461531487509764
0.03813033395759126
-0.3056586259551529
0.0884415243141502
-0.401132540383702
-0.4958673412728088
0.6000840121178136
-0.4239462436669685
-0.268279950699434
0.6382428304435708
-0.3934136192741355
-0.5189958548759737
0.39232075529961974
-0.33494466819106944
-0.12751192844933787
-0.10306106679302691
-0.1756612585412063
-0.11015532815232508
-0.0039350500347662834
0.27059468833135486
0.35437866308086613
-0.07064384640463149
0.08023000973766561
-0.3430910448099201
-0.18236691589407075
-0.15774112170947502
-0.08275779080989498
-0.2758923072029046
-0.3592471460049577
0.21964659633636763
0.16201031119085302
-0.38185084426177435
0.28366438683018164
-0.07203065379219999
-0.3718281838187709
-0.1902519138084298
0.6010811795083157
0.07608293878064218
-0.09731244539869144
0.07095074017530431
-0.15670674679749141
0.2204692413275874
2.990865091591019E-5
2.264959970602346E-4
0.011533827202263347
0.07327394466920958
-0.2901301622274088
0.04824978589634523
0.12885530463071704
0.034179911472099096
0.13404628012446593
-0.06908433952981531
0.13771364171208653
-0.23885443654600144
0.054737857627671915
0.17640638853905843
-0.04803943404351429
-0.18979985239844127
0.1943214547708019
-0.4475983103728413
0.08450791115907616
-0.1534166980042567
0.06193860020159102
-0.05759136663231431
-0.01767542434852982
-0.027689222370629332
-0.5685943531209833
0.1486600810076704
0.025783172936808044
0.12875687004710867
-0.3445187005657626
-0.2635712205090304
-0.2839513451256067
-0.30109657828914344
-0.21598565362095773
0.1769870608281722
-0.3164414632794343
0.6747402175716265
-0.2770057412436123
-0.6354233324659783
0.0957180125978232
-0.16432610957045862
0.49866381547353467
-0.7824844663199109
0.013969236815329541
-0.27089991849156314
6.304721523485558


---------------------------------

import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}

val paramGrid = new ParamGridBuilder().addGrid(lr.regParam, Array(0.1, 0.01, 0.001)).addGrid(lr.fitIntercept).addGrid(lr.maxIter, Array(100,300,500)).build()

import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator

val cv = new CrossValidator()
.setEstimator(pipeline)
.setEvaluator(new BinaryClassificationEvaluator)
.setEstimatorParamMaps(paramGrid)
.setNumFolds(3)

val model = cv.fit(trainingData)

import org.apache.spark.ml.PipelineModel
val bestmodel = model.bestModel.asInstanceOf[PipelineModel]

import org.apache.spark.ml.classification.LogisticRegressionModel
val lrmodel = bestmodel.stages(8).asInstanceOf[LogisticRegressionModel]

println(s"LR Model coefficients:\n${lrmodel.coefficients.toArray.mkString("\n")}")
LR Model coefficients:
0.025904285196891978
0.15699979140976425
-0.2658647269717539
0.03634999096834422
-0.9751234584405507
-0.18703541769267346
0.8037593629419529
0.6588199011500145
-1.2448891546442917
-0.2003215603142709
0.335380117716065
1.3976717394075642
1.8692973474427186
0.43454541238093547
-1.0641387187370168
0.677616986967713
-1.1864884953817023
-1.6488265092673124
2.5479498748172142
-1.5549347972679801
-0.753224632692895
2.5939214045055765
-1.5627358972021324
-2.3691714523854563
1.2309724464575884
-1.4974965490934231
-0.9284212746114003
-1.1263406443141994
-1.0883228152814621
-0.9280566395860558

val pred = bestmodel.transform(testData)

val bceval = new BinaryClassificationEvaluator()

bceval.evaluate(pred)
res3: Double = 0.8658914153089203
