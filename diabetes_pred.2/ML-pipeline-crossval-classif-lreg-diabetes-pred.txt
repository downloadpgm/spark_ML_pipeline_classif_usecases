---- Exploratory Data Analysis --------------

val df = spark.read.format("csv").option("header","true").option("inferSchema","true").load("diabetes_pred/diabetes_data_upload.csv")

df.printSchema
root
 |-- Age: integer (nullable = true)
 |-- Gender: string (nullable = true)
 |-- Polyuria: string (nullable = true)
 |-- Polydipsia: string (nullable = true)
 |-- sudden weight loss: string (nullable = true)
 |-- weakness: string (nullable = true)
 |-- Polyphagia: string (nullable = true)
 |-- Genital thrush: string (nullable = true)
 |-- visual blurring: string (nullable = true)
 |-- Itching: string (nullable = true)
 |-- Irritability: string (nullable = true)
 |-- delayed healing: string (nullable = true)
 |-- partial paresis: string (nullable = true)
 |-- muscle stiffness: string (nullable = true)
 |-- Alopecia: string (nullable = true)
 |-- Obesity: string (nullable = true)
 |-- class: string (nullable = true)

df.show(10)
+---+------+--------+----------+------------------+--------+----------+--------------+---------------+-------+------------+---------------+---------------+----------------+--------+-------+--------+
|Age|Gender|Polyuria|Polydipsia|sudden weight loss|weakness|Polyphagia|Genital thrush|visual blurring|Itching|Irritability|delayed healing|partial paresis|muscle stiffness|Alopecia|Obesity|   class|
+---+------+--------+----------+------------------+--------+----------+--------------+---------------+-------+------------+---------------+---------------+----------------+--------+-------+--------+
| 40|  Male|      No|       Yes|                No|     Yes|        No|            No|             No|    Yes|          No|            Yes|             No|             Yes|     Yes|    Yes|Positive|
| 58|  Male|      No|        No|                No|     Yes|        No|            No|            Yes|     No|          No|             No|            Yes|              No|     Yes|     No|Positive|
| 41|  Male|     Yes|        No|                No|     Yes|       Yes|            No|             No|    Yes|          No|            Yes|             No|             Yes|     Yes|     No|Positive|
| 45|  Male|      No|        No|               Yes|     Yes|       Yes|           Yes|             No|    Yes|          No|            Yes|             No|              No|      No|     No|Positive|
| 60|  Male|     Yes|       Yes|               Yes|     Yes|       Yes|            No|            Yes|    Yes|         Yes|            Yes|            Yes|             Yes|     Yes|    Yes|Positive|
| 55|  Male|     Yes|       Yes|                No|     Yes|       Yes|            No|            Yes|    Yes|          No|            Yes|             No|             Yes|     Yes|    Yes|Positive|
| 57|  Male|     Yes|       Yes|                No|     Yes|       Yes|           Yes|             No|     No|          No|            Yes|            Yes|              No|      No|     No|Positive|
| 66|  Male|     Yes|       Yes|               Yes|     Yes|        No|            No|            Yes|    Yes|         Yes|             No|            Yes|             Yes|      No|     No|Positive|
| 67|  Male|     Yes|       Yes|                No|     Yes|       Yes|           Yes|             No|    Yes|         Yes|             No|            Yes|             Yes|      No|    Yes|Positive|
| 70|  Male|      No|       Yes|               Yes|     Yes|       Yes|            No|            Yes|    Yes|         Yes|             No|             No|              No|     Yes|     No|Positive|
+---+------+--------+----------+------------------+--------+----------+--------------+---------------+-------+------------+---------------+---------------+----------------+--------+-------+--------+
only showing top 10 rows


df.describe().show
+-------+------------------+------+--------+----------+------------------+--------+----------+--------------+---------------+-------+------------+---------------+---------------+----------------+--------+-------+--------+
|summary|               Age|Gender|Polyuria|Polydipsia|sudden weight loss|weakness|Polyphagia|Genital thrush|visual blurring|Itching|Irritability|delayed healing|partial paresis|muscle stiffness|Alopecia|Obesity|   class|
+-------+------------------+------+--------+----------+------------------+--------+----------+--------------+---------------+-------+------------+---------------+---------------+----------------+--------+-------+--------+
|  count|               520|   520|     520|       520|               520|     520|       520|           520|            520|    520|         520|            520|            520|             520|     520|    520|     520|
|   mean| 48.02884615384615|  null|    null|      null|              null|    null|      null|          null|           null|   null|        null|           null|           null|            null|    null|   null|    null|
| stddev|12.151465995249454|  null|    null|      null|              null|    null|      null|          null|           null|   null|        null|           null|           null|            null|    null|   null|    null|
|    min|                16|Female|      No|        No|                No|      No|        No|            No|             No|     No|          No|             No|             No|              No|      No|     No|Negative|
|    max|                90|  Male|     Yes|       Yes|               Yes|     Yes|       Yes|           Yes|            Yes|    Yes|         Yes|            Yes|            Yes|             Yes|     Yes|    Yes|Positive|
+-------+------------------+------+--------+----------+------------------+--------+----------+--------------+---------------+-------+------------+---------------+---------------+----------------+--------+-------+--------+

df.groupBy("class").count.show
+--------+-----+
|class   |count|
+--------+-----+
|Negative|  200|
|Positive|  320|
+--------+-----+

---- Feature extraction & Data Munging --------------

val df1 = df.na.replace(Array("Polyuria","Polydipsia","sudden weight loss","weakness","Polyphagia","Genital thrush","visual blurring","Itching","Irritability","delayed healing","partial paresis","muscle stiffness","Alopecia","Obesity"),Map("No" -> "0.0", "Yes" -> "1.0")).
      na.replace(Array("class"),Map("Negative" -> "0.0", "Positive" -> "1.0")).
      na.replace(Array("Gender"),Map("Female" -> "0.0", "Male" -> "1.0")).
      withColumn("label", 'class)
  
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

val types = df1.dtypes
types: Array[(String, String)] = Array((Age,IntegerType), (Gender,StringType), (Polyuria,StringType), (Polydipsia,StringType), (sudden weight loss,StringType), (weakness,StringType), (Polyphagia,StringType), (Genital thrush,StringType), (visual blurring,StringType), (Itching,StringType), (Irritability,StringType), (delayed healing,StringType), (partial paresis,StringType), (muscle stiffness,StringType), (Alopecia,StringType), (Obesity,StringType), (class,StringType), (label,StringType))

df1.select(types.map{ case(c,t) => col(c).cast(DoubleType)}: _*)
res13: org.apache.spark.sql.DataFrame = [Age: double, Gender: double ... 16 more fields]

val df2 = df1.select(types.map{ case(c,t) => col(c).cast(DoubleType)}: _*)
df2: org.apache.spark.sql.DataFrame = [Age: double, Gender: double ... 16 more fields]

df2.printSchema
root
 |-- Age: double (nullable = true)
 |-- Gender: double (nullable = true)
 |-- Polyuria: double (nullable = true)
 |-- Polydipsia: double (nullable = true)
 |-- sudden weight loss: double (nullable = true)
 |-- weakness: double (nullable = true)
 |-- Polyphagia: double (nullable = true)
 |-- Genital thrush: double (nullable = true)
 |-- visual blurring: double (nullable = true)
 |-- Itching: double (nullable = true)
 |-- Irritability: double (nullable = true)
 |-- delayed healing: double (nullable = true)
 |-- partial paresis: double (nullable = true)
 |-- muscle stiffness: double (nullable = true)
 |-- Alopecia: double (nullable = true)
 |-- Obesity: double (nullable = true)
 |-- class: double (nullable = true)
 |-- label: double (nullable = true)


import org.apache.spark.ml.feature.VectorAssembler

val va = new VectorAssembler().setOutputCol("features").setInputCols(Array("Age","Gender","Polyuria","Polydipsia","sudden weight loss","weakness","Polyphagia","Genital thrush","visual blurring","Itching","Irritability","delayed healing","partial paresis","muscle stiffness","Alopecia","Obesity"))

val df3 = va.transform(df2)

df3.printSchema
root
 |-- Age: double (nullable = true)
 |-- Gender: double (nullable = true)
 |-- Polyuria: double (nullable = true)
 |-- Polydipsia: double (nullable = true)
 |-- sudden weight loss: double (nullable = true)
 |-- weakness: double (nullable = true)
 |-- Polyphagia: double (nullable = true)
 |-- Genital thrush: double (nullable = true)
 |-- visual blurring: double (nullable = true)
 |-- Itching: double (nullable = true)
 |-- Irritability: double (nullable = true)
 |-- delayed healing: double (nullable = true)
 |-- partial paresis: double (nullable = true)
 |-- muscle stiffness: double (nullable = true)
 |-- Alopecia: double (nullable = true)
 |-- Obesity: double (nullable = true)
 |-- class: double (nullable = true)
 |-- label: double (nullable = true)
 |-- features: vector (nullable = true)
 
df3.show(10)
+----+------+--------+----------+------------------+--------+----------+--------------+---------------+-------+------------+---------------+---------------+----------------+--------+-------+-----+-----+--------------------+
| Age|Gender|Polyuria|Polydipsia|sudden weight loss|weakness|Polyphagia|Genital thrush|visual blurring|Itching|Irritability|delayed healing|partial paresis|muscle stiffness|Alopecia|Obesity|class|label|            features|
+----+------+--------+----------+------------------+--------+----------+--------------+---------------+-------+------------+---------------+---------------+----------------+--------+-------+-----+-----+--------------------+
|40.0|   1.0|     0.0|       1.0|               0.0|     1.0|       0.0|           0.0|            0.0|    1.0|         0.0|            1.0|            0.0|             1.0|     1.0|    1.0|  1.0|  1.0|(16,[0,1,3,5,9,11...|
|58.0|   1.0|     0.0|       0.0|               0.0|     1.0|       0.0|           0.0|            1.0|    0.0|         0.0|            0.0|            1.0|             0.0|     1.0|    0.0|  1.0|  1.0|(16,[0,1,5,8,12,1...|
|41.0|   1.0|     1.0|       0.0|               0.0|     1.0|       1.0|           0.0|            0.0|    1.0|         0.0|            1.0|            0.0|             1.0|     1.0|    0.0|  1.0|  1.0|(16,[0,1,2,5,6,9,...|
|45.0|   1.0|     0.0|       0.0|               1.0|     1.0|       1.0|           1.0|            0.0|    1.0|         0.0|            1.0|            0.0|             0.0|     0.0|    0.0|  1.0|  1.0|(16,[0,1,4,5,6,7,...|
|60.0|   1.0|     1.0|       1.0|               1.0|     1.0|       1.0|           0.0|            1.0|    1.0|         1.0|            1.0|            1.0|             1.0|     1.0|    1.0|  1.0|  1.0|[60.0,1.0,1.0,1.0...|
|55.0|   1.0|     1.0|       1.0|               0.0|     1.0|       1.0|           0.0|            1.0|    1.0|         0.0|            1.0|            0.0|             1.0|     1.0|    1.0|  1.0|  1.0|[55.0,1.0,1.0,1.0...|
|57.0|   1.0|     1.0|       1.0|               0.0|     1.0|       1.0|           1.0|            0.0|    0.0|         0.0|            1.0|            1.0|             0.0|     0.0|    0.0|  1.0|  1.0|(16,[0,1,2,3,5,6,...|
|66.0|   1.0|     1.0|       1.0|               1.0|     1.0|       0.0|           0.0|            1.0|    1.0|         1.0|            0.0|            1.0|             1.0|     0.0|    0.0|  1.0|  1.0|[66.0,1.0,1.0,1.0...|
|67.0|   1.0|     1.0|       1.0|               0.0|     1.0|       1.0|           1.0|            0.0|    1.0|         1.0|            0.0|            1.0|             1.0|     0.0|    1.0|  1.0|  1.0|[67.0,1.0,1.0,1.0...|
|70.0|   1.0|     0.0|       1.0|               1.0|     1.0|       1.0|           0.0|            1.0|    1.0|         1.0|            0.0|            0.0|             0.0|     1.0|    0.0|  1.0|  1.0|[70.0,1.0,0.0,1.0...|
+----+------+--------+----------+------------------+--------+----------+--------------+---------------+-------+------------+---------------+---------------+----------------+--------+-------+-----+-----+--------------------+
only showing top 10 rows

// calculate pearson correlation to check multicolinearity

import org.apache.spark.ml.stat.Correlation
import org.apache.spark.ml.linalg.Matrix
import org.apache.spark.sql.Row

val corr = Correlation.corr(df3, "features", "pearson").head match {
   case Row(coeff: Matrix) => coeff
}
corr: org.apache.spark.ml.linalg.Matrix =
1.0                  0.06287207235698071    ... (16 total)
0.06287207235698071  1.0                    ...
0.19978075334739312  -0.26889367319563273   ...
0.13738159841543351  -0.3122617085919867    ...
0.0648083523423491   -0.28184010354962535   ...
0.2245955814796513   -0.12448966582906787   ...
0.3155768635050646   -0.21996805389192126   ...
0.09651861731004621  0.20896096685895094    ...
0.4027293484862436   -0.2080922874470089    ...
0.2965588901960364   -0.05249649746784866   ...
0.2016245924307449   -0.013735368023980257  ...
0.25750100691357225  -0.10197761974642187   ...
0.23274234710316322  -0.332288336507089     ...
0.30770276984767947  -0.09054187969287905   ...
0.3216913282501367   0.3278713061899102     ...
0.14045833557951048  -0....


corr.toDense.rowIter.foreach( x => {
     |   val size = x.size
     |   for ( i <- Range(0,size)) {
     |     val elem = x(i)
     |     print(f"$elem%.3f\t")
     |   }
     |   println
     | })
// "Age","Gender","Polyuria","Polydipsia","sudden weight loss","weakness","Polyphagia","Genital thrush","visual blurring","Itching","Irritability","delayed healing","partial paresis","muscle stiffness","Alopecia","Obesity"
1.000   0.063   0.200   0.137   0.065   0.225   0.316   0.097   0.403   0.297  0.202    0.258   0.233   0.308   0.322   0.140
0.063   1.000   -0.269  -0.312  -0.282  -0.124  -0.220  0.209   -0.208  -0.052 -0.014   -0.102  -0.332  -0.091  0.328   -0.005
0.200   -0.269  1.000   0.599   0.447   0.263   0.374   0.087   0.235   0.088  0.238    0.150   0.442   0.153   -0.144  0.127
0.137   -0.312  0.599   1.000   0.406   0.332   0.317   0.028   0.331   0.129  0.203    0.116   0.442   0.181   -0.311  0.099
0.065   -0.282  0.447   0.406   1.000   0.283   0.244   0.090   0.069   -0.005 0.140    0.088   0.264   0.110   -0.203  0.169
0.225   -0.124  0.263   0.332   0.283   1.000   0.180   0.028   0.301   0.309  0.147    0.336   0.273   0.263   0.090   0.046
0.316   -0.220  0.374   0.317   0.244   0.180   1.000   -0.064  0.294   0.144  0.239    0.264   0.374   0.320   -0.053  0.030
0.097   0.209   0.087   0.028   0.090   0.028   -0.064  1.000   -0.148  0.125  0.161    0.136   -0.196  -0.100  0.205   0.054
0.403   -0.208  0.235   0.331   0.069   0.301   0.294   -0.148  1.000   0.291  0.077    0.178   0.364   0.412   0.015   0.109
0.297   -0.052  0.088   0.129   -0.005  0.309   0.144   0.125   0.291   1.000  0.114    0.453   0.117   0.216   0.267   0.002
0.202   -0.014  0.238   0.203   0.140   0.147   0.239   0.161   0.077   0.114  1.000    0.127   0.152   0.202   0.044   0.128
0.258   -0.102  0.150   0.116   0.088   0.336   0.264   0.136   0.178   0.453  0.127    1.000   0.187   0.250   0.290   -0.066
0.233   -0.332  0.442   0.442   0.264   0.273   0.374   -0.196  0.364   0.117  0.152    0.187   1.000   0.233   -0.222  -0.009
0.308   -0.091  0.153   0.181   0.110   0.263   0.320   -0.100  0.412   0.216  0.202    0.250   0.233   1.000   0.041   0.159
0.322   0.328   -0.144  -0.311  -0.203  0.090   -0.053  0.205   0.015   0.267  0.044    0.290   -0.222  0.041   1.000   0.029
0.140   -0.005  0.127   0.099   0.169   0.046   0.030   0.054   0.109   0.002  0.128    -0.066  -0.009  0.159   0.029   1.000

// there is NO evidence of multicolinearity


// ----- building the logistic regression model

import org.apache.spark.ml.feature.StandardScaler
val stdScaler = new StandardScaler().
setWithStd(true).
setWithMean(true).
setInputCol("features").
setOutputCol("scaledFeatures")

import org.apache.spark.ml.classification.LogisticRegression
val lr = new LogisticRegression
lr.setRegParam(0.01).setMaxIter(100).setFitIntercept(true).setFeaturesCol("scaledFeatures")

import org.apache.spark.ml.Pipeline
val pipeline = new Pipeline().setStages(Array(va,stdScaler,lr))

val Array(trainingData, testData) = df2.randomSplit(Array(0.7,0.3),11L)

val model = pipeline.fit(trainingData)

-- collecting feature importance

import org.apache.spark.ml.classification.LogisticRegressionModel

val lrmodel = model.stages.last.asInstanceOf[LogisticRegressionModel]

val featureImp = va.getInputCols.zip(lrmodel.coefficients.toArray)

val columns = Array("feature", "Importance")
val featureImpDF = spark.createDataFrame(featureImp).toDF(columns: _*)

featureImpDF.orderBy($"Importance".desc).show()
+------------------+--------------------+
|           feature|          Importance|
+------------------+--------------------+
|        Polydipsia|  1.3561435255904153|
|          Polyuria|   1.266929438867989|
|      Irritability|   0.759354527397228|
|    Genital thrush|   0.518836404444447|
|   partial paresis|  0.4567697886741777|
|sudden weight loss| 0.34632330032266495|
|        Polyphagia|  0.2452477289034843|
|   visual blurring|  0.2278058935699796|
|          weakness| 0.17857229822254198|
|           Obesity|-0.09231938186022055|
|               Age|-0.09728127826946179|
|          Alopecia|-0.14972494229268168|
|  muscle stiffness|-0.18166280808138677|
|   delayed healing| -0.3932361656761581|
|           Itching|  -0.516832627982378|
|            Gender| -1.2344954156053858|
+------------------+--------------------+

// -----  metrics extracted from model

import org.apache.spark.ml.classification.BinaryLogisticRegressionSummary

val trainingSummary = lrmodel.summary

trainingSummary.objectiveHistory
res3: Array[Double] = Array(0.6730116670092521, 0.33824232040017166, 0.2899609595749758, 0.24511563870522957, 0.2261389515983281, 0.2223248903075804, 0.21995977431666675, 0.21986328991327583, 0.21982346585352386, 0.2197955821748887, 0.21979228387808522, 0.21979191750883667, 0.21979184927343498, 0.21979183631389201, 0.21979183146318645, 0.21979183132081015, 0.21979183063501617, 0.21979183060441884, 0.21979183058260587, 0.21979183058216886)

val binarySummary = trainingSummary.asInstanceOf[BinaryLogisticRegressionSummary]

binarySummary.areaUnderROC
res4: Double = 0.9799524613748669

binarySummary.accuracy
res5: Double = 0.9315068493150684


// -----  metrics on test data

val pred = model.transform(testData)

import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator
val bceval = new BinaryClassificationEvaluator()

bceval.setMetricName("areaUnderROC").evaluate(pred)
res6: Double = 0.9717638430509716

bceval.setMetricName("areaUnderPR").evaluate(pred)
res7: Double = 0.9879640674546408


val validPredicts = pred.select("label","prediction").rdd.map( row => (row.getDouble(0),row.getDouble(1)) )

import org.apache.spark.mllib.evaluation.MulticlassMetrics
val metrics = new MulticlassMetrics(validPredicts)

metrics.accuracy
res8: Double = 0.9483870967741935

metrics.confusionMatrix
res9: org.apache.spark.mllib.linalg.Matrix =
52.0  6.0
2.0   95.0


// ----- logistic regression model hyperparameter tunning

import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}

val paramGrid = new ParamGridBuilder().
addGrid(lr.regParam, Array(1, 0.1, 0.01, 0.001)).
addGrid(lr.fitIntercept).
addGrid(lr.maxIter, Array(10, 20, 40, 100)).build()

import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator
val bce = new BinaryClassificationEvaluator

val cv = new CrossValidator().
setEstimator(pipeline).
setEvaluator(bce.setMetricName("areaUnderROC")).
setEstimatorParamMaps(paramGrid).
setNumFolds(3)

val cvmodel = cv.fit(trainingData)

-- CV hyperparameter evaluation

cvmodel.getEstimatorParamMaps.zip(cvmodel.avgMetrics)
res10: Array[(org.apache.spark.ml.param.ParamMap, Double)] =
Array(({
        logreg_8820ac2638d7-fitIntercept: true,
        logreg_8820ac2638d7-maxIter: 10,
        logreg_8820ac2638d7-regParam: 1.0
},0.9564730221285483), ({
        logreg_8820ac2638d7-fitIntercept: true,
        logreg_8820ac2638d7-maxIter: 10,
        logreg_8820ac2638d7-regParam: 0.1
},0.9709532142925806), ({
        logreg_8820ac2638d7-fitIntercept: true,
        logreg_8820ac2638d7-maxIter: 10,
        logreg_8820ac2638d7-regParam: 0.01
},0.9730688497870031), ({
        logreg_8820ac2638d7-fitIntercept: true,
        logreg_8820ac2638d7-maxIter: 10,
        logreg_8820ac2638d7-regParam: 0.001
},0.9721376565800625), ({
        logreg_8820ac2638d7-fitIntercept: false,
        logreg_8820ac2638d7-maxIter: 10,
        logreg_8820ac2638d7-regParam: 1.0
},0.9564910458176685), ({
        logreg_8820ac2638d7-fitIntercept: false,
        ...


-- extract best LR model 

import org.apache.spark.ml.PipelineModel
val bestmodel = cvmodel.bestModel.asInstanceOf[PipelineModel]

import org.apache.spark.ml.classification.LogisticRegressionModel
val lrmodel = bestmodel.stages.last.asInstanceOf[LogisticRegressionModel]

lrmodel.getRegParam
res11: Double = 0.01

lrmodel.getMaxIter
res12: Int = 10

lrmodel.getThreshold
res13: Double = 0.5

lrmodel.getFitIntercept
res14: Boolean = true


-- collecting feature importance

val featureImp = va.getInputCols.zip(lrmodel.coefficients.toArray)

val columns = Array("feature", "Importance")
val featureImpDF = spark.createDataFrame(featureImp).toDF(columns: _*)

featureImpDF.orderBy($"Importance".desc).show()
+------------------+--------------------+
|           feature|          Importance|
+------------------+--------------------+
|        Polydipsia|   1.356735467133985|
|          Polyuria|  1.2689238148780568|
|      Irritability|  0.7600925048588555|
|    Genital thrush|  0.5183595100151677|
|   partial paresis| 0.45647416230809595|
|sudden weight loss| 0.34628972221973175|
|        Polyphagia| 0.24582484890294778|
|   visual blurring| 0.22977277137907454|
|          weakness| 0.17787239339663163|
|           Obesity|-0.09336910202277421|
|               Age|-0.09726027644785243|
|          Alopecia| -0.1496818928945016|
|  muscle stiffness|-0.18137708194084315|
|   delayed healing|-0.39375546555300983|
|           Itching| -0.5180627231386878|
|            Gender| -1.2338681432002692|
+------------------+--------------------+


import org.apache.spark.ml.classification.BinaryLogisticRegressionSummary

val trainingSummary = lrmodel.summary

trainingSummary.objectiveHistory
res16: Array[Double] = Array(0.6730116670092521, 0.33824232040017166, 0.2899609595749758, 0.24511563870522957, 0.2261389515983281, 0.2223248903075804, 0.21995977431666675, 0.21986328991327583, 0.21982346585352386, 0.2197955821748887, 0.21979228387808522)

val binarySummary = trainingSummary.asInstanceOf[BinaryLogisticRegressionSummary]

binarySummary.areaUnderROC
res17: Double = 0.9799524613748669

binarySummary.accuracy
res18: Double = 0.9315068493150684


-- collecting metric performance

val pred = bestmodel.transform(testData)

val bceval = new BinaryClassificationEvaluator()

bceval.setMetricName("areaUnderROC").evaluate(pred)
res19: Double = 0.9717638430509716

bceval.setMetricName("areaUnderPR").evaluate(pred)
res20: Double = 0.9879640674546408

val validPredicts = pred.select("label","prediction").rdd.map( row => (row.getDouble(0),row.getDouble(1)) )

import org.apache.spark.mllib.evaluation.MulticlassMetrics
val metrics = new MulticlassMetrics(validPredicts)

metrics.accuracy
res21: Double = 0.9483870967741935

metrics.confusionMatrix
res22: org.apache.spark.mllib.linalg.Matrix =
52.0  6.0
2.0   95.0
