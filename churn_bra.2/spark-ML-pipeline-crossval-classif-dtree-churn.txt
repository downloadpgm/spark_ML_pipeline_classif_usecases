---- Exploratory Data Analysis --------------

val df = spark.read.format("csv").option("header","true").option("inferSchema","true").load("spark/churn_bra/dados_clientes.csv").drop("id")

df.printSchema
root
 |-- Churn: string (nullable = true)
 |-- Mais65anos: integer (nullable = true)
 |-- Conjuge: string (nullable = true)
 |-- Dependentes: string (nullable = true)
 |-- MesesDeContrato: integer (nullable = true)
 |-- TelefoneFixo: string (nullable = true)
 |-- MaisDeUmaLinhaTelefonica: string (nullable = true)
 |-- Internet: string (nullable = true)
 |-- SegurancaOnline: string (nullable = true)
 |-- BackupOnline: string (nullable = true)
 |-- SeguroDispositivo: string (nullable = true)
 |-- SuporteTecnico: string (nullable = true)
 |-- TVaCabo: string (nullable = true)
 |-- StreamingFilmes: string (nullable = true)
 |-- TipoContrato: string (nullable = true)
 |-- ContaCorreio: string (nullable = true)
 |-- MetodoPagamento: string (nullable = true)
 |-- MesesCobrados: double (nullable = true)


df.describe().show
+-------+-----+------------------+-------+-----------+------------------+------------+------------------------+--------+---------------+------------+-----------------+--------------+-------+---------------+------------+------------+---------------+------------------+-----+
|summary|Churn|        Mais65anos|Conjuge|Dependentes|   MesesDeContrato|TelefoneFixo|MaisDeUmaLinhaTelefonica|Internet|SegurancaOnline|BackupOnline|SeguroDispositivo|SuporteTecnico|TVaCabo|StreamingFilmes|TipoContrato|ContaCorreio|MetodoPagamento|     MesesCobrados|label|
+-------+-----+------------------+-------+-----------+------------------+------------+------------------------+--------+---------------+------------+-----------------+--------------+-------+---------------+------------+------------+---------------+------------------+-----+
|  count|10348|             10348|  10348|      10348|             10348|       10348|                   10348|   10348|          10348|       10348|            10348|         10348|  10348|          10348|       10348|       10348|          10348|             10348|10348|
|   mean| null|0.1409934286818709|   null|       null|27.518554310011595|        null|                    null|    null|           null|        null|             null|          null|   null|           null|        null|        null|           null| 67.72477324116379| null|
| stddev| null|0.3480315890924261|   null|       null| 24.09778298180764|        null|                    null|    null|           null|        null|             null|          null|   null|           null|        null|        null|           null|28.859250112596182| null|
|    min|  Nao|                 0|    Nao|        Nao|                 0|         Nao|                     Nao|     DSL|            Nao|         Nao|              Nao|           Nao|    Nao|            Nao|    DoisAnos|         Nao|         Boleto|             18.25|  Nao|
|    max|  Sim|                 1|    Sim|        Sim|                72|         Sim|                     Sim|     Nao|            Sim|         Sim|              Sim|           Sim|    Sim|            Sim|       UmAno|         Sim|  DebitoEmConta|            118.75|  Sim|
+-------+-----+------------------+-------+-----------+------------------+------------+------------------------+--------+---------------+------------+-----------------+--------------+-------+---------------+------------+------------+---------------+------------------+-----+

df.groupBy('TelefoneFixo,'MaisDeUmaLinhaTelefonica).count.show
+------------+------------------------+-----+
|TelefoneFixo|MaisDeUmaLinhaTelefonica|count|
+------------+------------------------+-----+
|         Sim|                     Sim| 4515|
|         Sim|                     Nao| 4848|
|         Nao|    SemServicoTelefonico|  985|
+------------+------------------------+-----+

df.groupBy('Internet,'SegurancaOnline).count.show
+-----------+------------------+-----+
|   Internet|   SegurancaOnline|count|
+-----------+------------------+-----+
|FibraOptica|               Sim| 1006|
|        DSL|               Nao| 1889|
|FibraOptica|               Nao| 4395|
|        Nao|SemServicoInternet| 1741|
|        DSL|               Sim| 1317|
+-----------+------------------+-----+

df.groupBy('Internet,'BackupOnline).count.show
+-----------+------------------+-----+
|   Internet|      BackupOnline|count|
+-----------+------------------+-----+
|FibraOptica|               Sim| 2069|
|        DSL|               Nao| 1965|
|FibraOptica|               Nao| 3332|
|        Nao|SemServicoInternet| 1741|
|        DSL|               Sim| 1241|
+-----------+------------------+-----+

df.groupBy('Internet,'SeguroDispositivo).count.show
+-----------+------------------+-----+
|   Internet| SeguroDispositivo|count|
+-----------+------------------+-----+
|FibraOptica|               Sim| 2072|
|        DSL|               Nao| 1962|
|FibraOptica|               Nao| 3329|
|        Nao|SemServicoInternet| 1741|
|        DSL|               Sim| 1244|
+-----------+------------------+-----+

df.groupBy('Internet,'SuporteTecnico).count.show
+-----------+------------------+-----+
|   Internet|    SuporteTecnico|count|
+-----------+------------------+-----+
|FibraOptica|               Sim| 1081|
|        DSL|               Nao| 1882|
|FibraOptica|               Nao| 4320|
|        Nao|SemServicoInternet| 1741|
|        DSL|               Sim| 1324|
+-----------+------------------+-----+

df.groupBy('Internet,'TVaCabo).count.show
+-----------+------------------+-----+
|   Internet|           TVaCabo|count|
+-----------+------------------+-----+
|FibraOptica|               Sim| 2994|
|        DSL|               Nao| 2052|
|FibraOptica|               Nao| 2407|
|        Nao|SemServicoInternet| 1741|
|        DSL|               Sim| 1154|
+-----------+------------------+-----+

df.groupBy('Internet,'StreamingFilmes).count.show
+-----------+------------------+-----+
|   Internet|   StreamingFilmes|count|
+-----------+------------------+-----+
|FibraOptica|               Sim| 2970|
|        DSL|               Nao| 2014|
|FibraOptica|               Nao| 2431|
|        Nao|SemServicoInternet| 1741|
|        DSL|               Sim| 1192|
+-----------+------------------+-----+

df.groupBy("Churn").count.show
+-----+-----+
|Churn|count|
+-----+-----+
|  Nao| 5174|
|  Sim| 5174|
+-----+-----+


---- Feature extraction & Data Munging --------------

import org.apache.spark.ml.feature.{StringIndexer, VectorAssembler}

val dfInd0 = new StringIndexer().setInputCol("Churn").setOutputCol("label")
val df2 = dfInd0.fit(df).transform(df)

val dfInd1 = new StringIndexer().setInputCol("Conjuge").setOutputCol("ConjugeCat")
val dfInd2 = new StringIndexer().setInputCol("Dependentes").setOutputCol("DependentesCat")
val dfInd3 = new StringIndexer().setInputCol("TelefoneFixo").setOutputCol("TelefoneFixoCat")
val dfInd4 = new StringIndexer().setInputCol("MaisDeUmaLinhaTelefonica").setOutputCol("MaisDeUmaLinhaCat")
val dfInd5 = new StringIndexer().setInputCol("Internet").setOutputCol("InternetCat")
val dfInd6 = new StringIndexer().setInputCol("SegurancaOnline").setOutputCol("SegurancaOnlineCat")
val dfInd7 = new StringIndexer().setInputCol("BackupOnline").setOutputCol("BackupOnlineCat")
val dfInd8 = new StringIndexer().setInputCol("SeguroDispositivo").setOutputCol("SeguroDispositivoCat")
val dfInd9 = new StringIndexer().setInputCol("SuporteTecnico").setOutputCol("SuporteTecnicoCat")
val dfInd10 = new StringIndexer().setInputCol("TVaCabo").setOutputCol("TVaCaboCat")
val dfInd11 = new StringIndexer().setInputCol("StreamingFilmes").setOutputCol("StreamingFilmesCat")
val dfInd12 = new StringIndexer().setInputCol("TipoContrato").setOutputCol("TipoContratoCat")
val dfInd13 = new StringIndexer().setInputCol("ContaCorreio").setOutputCol("ContaCorreioCat")
val dfInd14 = new StringIndexer().setInputCol("MetodoPagamento").setOutputCol("MetodoPagamentoCat")

val va = new VectorAssembler().setOutputCol("features").setInputCols(Array("Mais65anos","ConjugeCat","DependentesCat","MesesDeContrato","TelefoneFixoCat","MaisDeUmaLinhaCat","InternetCat","SegurancaOnlineCat","BackupOnlineCat","SeguroDispositivoCat","SuporteTecnicoCat","TVaCaboCat","StreamingFilmesCat","TipoContratoCat","ContaCorreioCat","MetodoPagamentoCat","MesesCobrados"))

// ----- building the decision tree model

import org.apache.spark.ml.classification.DecisionTreeClassifier
val dt = new DecisionTreeClassifier

import org.apache.spark.ml.Pipeline

val pipeline = new Pipeline().setStages(Array(dfInd1,dfInd2,dfInd3,dfInd4,dfInd5,dfInd6,dfInd7,dfInd8,dfInd9,dfInd10,dfInd11,dfInd12,dfInd13,dfInd14,va,dt))

val Array(trainingData, testData) = df2.randomSplit(Array(0.7,0.3),11L)

trainingData.cache
testData.cache


// ----- find best decision tree model

import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}

val paramGrid = new ParamGridBuilder().
addGrid(dt.maxBins, Array(32, 48, 64)).
addGrid(dt.impurity, Array("gini", "entropy")).
addGrid(dt.maxDepth, Array(10,20,30)).build()

import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator

val cv = new CrossValidator().
setEstimator(pipeline).
setEvaluator(new BinaryClassificationEvaluator).
setEstimatorParamMaps(paramGrid).
setNumFolds(3)

val cvmodel = cv.fit(trainingData)

-- CV hyperparameter evaluation

(new BinaryClassificationEvaluator).getMetricName
res10: String = areaUnderROC

cvmodel.getEstimatorParamMaps.zip(cvmodel.avgMetrics)
res7: Array[(org.apache.spark.ml.param.ParamMap, Double)] =
Array(({
        dtc_a5881d67b58b-impurity: gini,
        dtc_a5881d67b58b-maxBins: 32,
        dtc_a5881d67b58b-maxDepth: 10
},0.8339493683250033), ({
        dtc_a5881d67b58b-impurity: gini,
        dtc_a5881d67b58b-maxBins: 48,
        dtc_a5881d67b58b-maxDepth: 10
},0.8313540682666662), ({
        dtc_a5881d67b58b-impurity: gini,
        dtc_a5881d67b58b-maxBins: 64,
        dtc_a5881d67b58b-maxDepth: 10
},0.8334404126217366), ({
        dtc_a5881d67b58b-impurity: entropy,
        dtc_a5881d67b58b-maxBins: 32,
        dtc_a5881d67b58b-maxDepth: 10
},0.8300173246721615), ({
        dtc_a5881d67b58b-impurity: entropy,
        dtc_a5881d67b58b-maxBins: 48,
        dtc_a5881d67b58b-maxDepth: 10
},0.8265491347542308), ({
        dtc_a5881d67b58b-impurity: entropy,
        dtc_a5881d67b58b-maxBins: 64,
        dtc_a5881d67b58b-maxDepth: 10
},0.831583816...


// -----  metrics extracted from model

import org.apache.spark.ml.PipelineModel
val bestmodel = cvmodel.bestModel.asInstanceOf[PipelineModel]

import org.apache.spark.ml.classification.DecisionTreeClassificationModel
val dtmodel = bestmodel.stages(15).asInstanceOf[DecisionTreeClassificationModel]

dtmodel.getMaxBins
res0: Int = 32

dtmodel.getImpurity
res2: String = gini

dtmodel.getMaxDepth
res3: Int = 10

-- collecting feature importance

val featureImp = va.getInputCols.zip(dtmodel.featureImportances.toArray)

val columns = Array("feature", "Importance")
val featureImpDF = spark.createDataFrame(featureImp).toDF(columns: _*)

featureImpDF.orderBy($"Importance".desc).show()
+--------------------+--------------------+
|             feature|          Importance|
+--------------------+--------------------+
|     TipoContratoCat|  0.4202215656169429|
|     MesesDeContrato| 0.13728816350004672|
|  SegurancaOnlineCat| 0.08747581077681058|
|  MetodoPagamentoCat|  0.0743388747792081|
|       MesesCobrados|  0.0599834599487984|
|         InternetCat|  0.0394547638121862|
|     BackupOnlineCat| 0.02604067307540311|
|     ContaCorreioCat| 0.02580776713281502|
|   SuporteTecnicoCat|0.023295433049622956|
|      DependentesCat|0.019990747771904013|
|  StreamingFilmesCat|0.019692950617456854|
|          ConjugeCat|0.018272732753424892|
|   MaisDeUmaLinhaCat|0.012222683803216212|
|          Mais65anos|0.010103863955269538|
|SeguroDispositivoCat|0.009730558749696553|
|          TVaCaboCat|0.008655374831699208|
|     TelefoneFixoCat|0.007424575825498743|
+--------------------+--------------------+


// -----  metrics extracted from model

val pred = bestmodel.transform(testData)

val bceval = new BinaryClassificationEvaluator()

bceval.setMetricName("areaUnderROC").evaluate(pred)
res8: Double = 0.8355745133336863

bceval.setMetricName("areaUnderPR").evaluate(pred)
res9: Double = 0.810940579718696

val validPredicts = pred.select("label","prediction").rdd.map( row => (row.getDouble(0),row.getDouble(1)) )

import org.apache.spark.mllib.evaluation.MulticlassMetrics
val metrics = new MulticlassMetrics(validPredicts)

metrics.confusionMatrix
res10: org.apache.spark.mllib.linalg.Matrix =
1096.0  230.0
400.0   1285.0
